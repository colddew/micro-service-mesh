# nacos
spring.cloud.nacos.config.server-addr=192.168.0.14:8848
spring.cloud.nacos.config.namespace=prod
spring.config.import=optional:nacos:${spring.application.name}-k8s.properties?group=springcloud&refreshEnabled=true
spring.cloud.nacos.discovery.server-addr=192.168.0.14:8848
spring.cloud.nacos.discovery.namespace=prod
spring.cloud.nacos.discovery.group=springcloud
spring.cloud.nacos.discovery.failure-tolerance-enabled=true

# dubbo
dubbo.scan.base-packages=cn.plantlink.service.dubbo
dubbo.application.name=dubbo-server3
dubbo.registry.address=nacos://192.168.0.14:8848
#dubbo.protocol.name=dubbo
#dubbo.protocol.port=-1

# elasticsearch client compatible with Community ES 7.17.0 & Aliyun ES 7.10
elasticsearch.cluster.nodes=127.0.0.1:9200
elasticsearch.username=elastic
elasticsearch.password=elastic
elasticsearch.index.article=article
elasticsearch.index.product=product

# canal
canal.zkServers=127.0.0.1:2181,127.0.0.1:2182,127.0.0.1:2183
canal.destination.example=example
canal.destination.info=info
canal.client.switch=0

# kafka
spring.kafka.bootstrap-servers=127.0.0.1:9991,127.0.0.1:9992,127.0.0.1:9993
spring.kafka.producer.retries=0
spring.kafka.producer.acks=1
spring.kafka.producer.batch-size=4096
spring.kafka.producer.buffer-memory=40960
spring.kafka.producer.compression-type=gzip
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.consumer.group-id=test-group
spring.kafka.consumer.auto-offset-reset=latest
spring.kafka.consumer.enable-auto-commit=true
spring.kafka.consumer.auto-commit-interval=1000
spring.kafka.listener.poll-timeout=3000
#spring.kafka.listener.concurrency=3
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer

# es log level
logging.level.tracer=TRACE

# business config
server.local.config=k8s-local